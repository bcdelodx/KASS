{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7201f69",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "![KR-Labs Web Logo](data:image/png;base64,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)\n",
    "\n",
    "**KR-Labs** | Data-Driven Clarity for Community Growth\n",
    "\n",
    "Â© 2025 KR-Labs. All rights reserved.\n",
    "KASS notebooks and associated source code are licensed under the Apache License, Version 2.0.\n",
    "All other content, analytical frameworks, methodologies, system architectures, data models, and proprietary platforms referenced or described are excluded from this license and may not be reused without prior written consent.\n",
    "\n",
    "KASSâ„¢, KR-Labsâ„¢, and Khipu Researchâ„¢ are trademarks of Sundiata Giddasira, Inc.\n",
    "\n",
    "[krlabs.dev](https://krlabs.dev) | [info@krlabs.dev](mailto:info@krlabs.dev)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff889df4",
   "metadata": {},
   "source": [
    "**DATA PROVENANCE:** Real BLS/FRED macro data + Synthetic metro-level outcomes | See Limitations section for details\n",
    "\n",
    "---\n",
    "\n",
    "# Labor Market Intelligence Analysis\n",
    "\n",
    "## KASS Notebook | Applied Econometrics Series\n",
    "\n",
    "**KRL Suite v2.0** | **Tier: Community** | **Data: BLS + FRED**\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook demonstrates **comprehensive labor market intelligence** using descriptive econometric methods and real-time data from the Bureau of Labor Statistics (BLS) and Federal Reserve Economic Data (FRED).\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "\n",
    "1.  **Data Integration** - Combine employment, wage, and macroeconomic indicators from BLS and FRED APIs\n",
    "2.  **Industry Analysis** - Apply Location Quotient and Shift-Share decomposition to identify regional specializations\n",
    "3.  **Time Series Diagnostics** - Use STL decomposition to detect anomalies in labor market trends\n",
    "4.  **Correlation Analysis** - Examine relationships between labor market indicators and economic conditions\n",
    "5.  **Dashboard Creation** - Build executive-ready visualizations of labor market intelligence\n",
    "\n",
    "### Key Methods\n",
    "\n",
    "| Method | Purpose | KRL Component |\n",
    "|--------|---------|---------------|\n",
    "| Location Quotient | Regional industry specialization | `LocationQuotientModel` |\n",
    "| Shift-Share Analysis | Decompose employment change | `ShiftShareModel` |\n",
    "| STL Decomposition | Trend/seasonal/residual | `STLAnomalyModel` |\n",
    "| Correlation Analysis | Cross-indicator relationships | `scipy.stats` |\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- KRL Suite Community Tier\n",
    "- FRED API key (free registration at https://fred.stlouisfed.org/docs/api/api_key.html)\n",
    "- BLS API key (optional, for higher rate limits)\n",
    "\n",
    "### Estimated Time: 20-25 minutes\n",
    "\n",
    "---\n",
    "\n",
    "âš ï¸ **Analytical Framework Note:** This notebook performs **descriptive analytics**, not causal inference. Correlations and patterns identified should be interpreted as associations, not causal effects. See the Limitations section for proper interpretation guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c1437",
   "metadata": {},
   "source": [
    "## KRL Suite Components & Pricing\n",
    "\n",
    "This notebook uses the following KRL packages and tools:\n",
    "\n",
    "| Component | Package | Tier | Description |\n",
    "|-----------|---------|------|-------------|\n",
    "| `BLSBasicConnector` | `krl-data-connectors` | ðŸŸ¢ Community | Bureau of Labor Statistics data access |\n",
    "| `FREDBasicConnector` | `krl-data-connectors` | ðŸŸ¢ Community | Federal Reserve Economic Data (50 series) |\n",
    "| `LocationQuotientModel` | `krl-models` | ðŸŸ¢ Community | Industry concentration analysis |\n",
    "| `ShiftShareModel` | `krl-models` | ðŸŸ¢ Community | Bartik-style decomposition |\n",
    "| `STLAnomalyModel` | `krl-models` | ðŸŸ¢ Community | Seasonal-trend decomposition |\n",
    "| `get_logger` | `krl-core` | ðŸŸ¢ Community | Logging utilities |\n",
    "\n",
    "### Upgrade Options\n",
    "\n",
    "| Tier | Price | Features | Subscribe |\n",
    "|------|-------|----------|-----------|\n",
    "| **Community** | Free | Basic connectors, core models | [GitHub](https://github.com/KhipuResearch) |\n",
    "| **Professional** | $149/mo | Full FRED access (800k+ series), advanced models | [Subscribe â†’](https://buy.stripe.com/5kA8Am4hP9wE5qg3ce) |\n",
    "| **Enterprise** | Custom | Full platform, dedicated support | [Contact Sales](mailto:enterprise@khipuresearchlabs.com) |\n",
    "\n",
    "### Rental Passes (Pay-As-You-Go)\n",
    "\n",
    "| Duration | Price | Best For | Get Access |\n",
    "|----------|-------|----------|------------|\n",
    "| 1 Hour | $5 | Quick analysis | [Buy Pass â†’](https://buy.stripe.com/krl_1hr_pass) |\n",
    "| 24 Hours | $15 | Day project | [Buy Pass â†’](https://buy.stripe.com/krl_24hr_pass) |\n",
    "| 7 Days | $99 | Extended trial | [Buy Pass â†’](https://buy.stripe.com/krl_7day_trial) |\n",
    "\n",
    "> ðŸ’¡ **Tip**: This notebook runs fully on **Community tier** (free). No subscription required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846b33d",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "### Why Labor Market Intelligence Matters\n",
    "\n",
    "Labor market dynamics are fundamental to understanding economic health, policy effectiveness, and workforce development needs. Policymakers, researchers, and business leaders require comprehensive intelligence that goes beyond simple unemployment statistics:\n",
    "\n",
    "**1. Economic Monitoring**\n",
    "- Track business cycle dynamics through employment and wage trends\n",
    "- Identify early warning signs of labor market stress\n",
    "- Monitor recovery patterns following economic shocks\n",
    "\n",
    "**2. Regional Economic Development**\n",
    "- Assess industry specialization and competitive advantage\n",
    "- Identify skills gaps and training priorities\n",
    "- Support evidence-based workforce investment decisions\n",
    "\n",
    "**3. Policy Evaluation Context**\n",
    "- Establish baseline labor market conditions for policy analysis\n",
    "- Track leading and lagging indicators for impact timing\n",
    "- Monitor distributional effects across sectors and regions\n",
    "\n",
    "### Analytical Framework\n",
    "\n",
    "This notebook implements a **descriptive analytics pipeline** for labor market intelligence:\n",
    "\n",
    "```\n",
    "Data Collection â†’ Indicator Construction â†’ Pattern Detection â†’ Visualization\n",
    "     â†“                    â†“                       â†“                â†“\n",
    "  BLS/FRED          LQ, Shift-Share        STL Anomaly        Dashboards\n",
    "```\n",
    "\n",
    "**Important:** This is *descriptive*, not *causal* analysis. We identify patterns and correlations that inform decision-making but do not establish cause-and-effect relationships.\n",
    "\n",
    "### Policy Applications\n",
    "\n",
    "| Application | Descriptive Intelligence | Causal Analysis Needed |\n",
    "|-------------|-------------------------|----------------------|\n",
    "| Economic monitoring | âœ… This notebook | âŒ Not required |\n",
    "| Training needs assessment | âœ… Partial (skill gaps) | âš ï¸ For ROI claims |\n",
    "| Regional planning | âœ… Industry analysis | âš ï¸ For intervention effects |\n",
    "| Policy evaluation | âš ï¸ Context only | âœ… See causal inference notebooks |\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "| Source | Variables | Update Frequency | Access |\n",
    "|--------|-----------|------------------|--------|\n",
    "| BLS CES | Employment by industry | Monthly | Free API |\n",
    "| BLS QCEW | Wages, establishment counts | Quarterly | Free API |\n",
    "| BLS OES | Occupation-level wages | Annual | Free API |\n",
    "| FRED | GDP, CPI, macro indicators | Varies | Free API |\n",
    "\n",
    "---\n",
    "\n",
    "*For causal analysis of workforce interventions, see [22-workforce-development-roi.ipynb](22-workforce-development-roi.ipynb).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39835bd4",
   "metadata": {},
   "source": [
    "# Labor Market Intelligence Analysis\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook provides **comprehensive labor market analysis** using the KRL Suite to combine BLS employment data with economic indicators from FRED.\n",
    "\n",
    "### KRL Suite Components Used\n",
    "\n",
    "- **krl_data_connectors.community**: `BLSBasicConnector`, `FREDBasicConnector`\n",
    "- **krl_models**: `STLAnomalyModel` for detecting unusual labor market patterns\n",
    "- **krl_core**: Logging utilities\n",
    "\n",
    "### Key Intelligence Questions\n",
    "\n",
    "1. What are the trends in employment and wages?\n",
    "2. How does unemployment relate to other economic indicators?\n",
    "3. What sectors show the strongest labor market dynamics?\n",
    "4. What leading indicators predict labor market changes?\n",
    "\n",
    "**Estimated Time:** 20-25 minutes  \n",
    "**Difficulty:** Intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520827b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Labor Market Intelligence: Environment Setup\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Installation (public users):\n",
    "    pip install krl-core krl-data-connectors krl-models\n",
    "\n",
    "Development (contributors):\n",
    "    # Add to ~/.krl/.env:\n",
    "    # KRL_DEV_PATH=/your/local/path/to/krl-monorepo\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import importlib.util\n",
    "\n",
    "# =============================================================================\n",
    "# Load environment variables FIRST (before checking KRL_DEV_PATH)\n",
    "# =============================================================================\n",
    "from dotenv import load_dotenv\n",
    "for _env_file in [os.path.expanduser(\"~/.krl/.env\"), \".env\"]:\n",
    "    if os.path.exists(_env_file):\n",
    "        load_dotenv(_env_file)\n",
    "        break\n",
    "\n",
    "# =============================================================================\n",
    "# KRL Suite Path Configuration\n",
    "# =============================================================================\n",
    "# Priority: KRL_DEV_PATH env var > pip-installed packages\n",
    "_KRL_DEV_PATH = os.environ.get(\"KRL_DEV_PATH\")\n",
    "\n",
    "if _KRL_DEV_PATH and os.path.isdir(_KRL_DEV_PATH):\n",
    "    # Developer mode: use local clones\n",
    "    _krl_base = _KRL_DEV_PATH\n",
    "    for _pkg in [\"krl-open-core/src\", \"krl-data-connectors/src\"]:\n",
    "        _path = os.path.join(_krl_base, _pkg)\n",
    "        if os.path.isdir(_path) and _path not in sys.path:\n",
    "            sys.path.insert(0, _path)\n",
    "    \n",
    "    # Add Model Catalog path for krl_models\n",
    "    _model_catalog_path = os.path.join(_krl_base, \"Model Catalog\")\n",
    "    if os.path.isdir(_model_catalog_path) and _model_catalog_path not in sys.path:\n",
    "        sys.path.insert(0, _model_catalog_path)\n",
    "    \n",
    "    # Create krl_models module alias pointing to Class A folder\n",
    "    _class_a_init = os.path.join(_model_catalog_path, \"Class A\", \"__init__.py\")\n",
    "    if os.path.exists(_class_a_init) and \"krl_models\" not in sys.modules:\n",
    "        _spec = importlib.util.spec_from_file_location(\"krl_models\", _class_a_init)\n",
    "        _krl_models = importlib.util.module_from_spec(_spec)\n",
    "        sys.modules[\"krl_models\"] = _krl_models\n",
    "        _krl_models.__path__ = [os.path.join(_model_catalog_path, \"Class A\")]\n",
    "        _spec.loader.exec_module(_krl_models)\n",
    "    \n",
    "    _INSTALL_MODE = \"development\"\n",
    "else:\n",
    "    # Production mode: pip-installed packages (no path manipulation needed)\n",
    "    _INSTALL_MODE = \"pip\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# Suppress verbose connector logging\n",
    "# =============================================================================\n",
    "import logging\n",
    "for _logger_name in ['FREDFullConnector', 'FREDBasicConnector', 'BLSBasicConnector', \n",
    "                     'BLSEnhancedConnector', 'CensusConnector', 'krl_data_connectors']:\n",
    "    logging.getLogger(_logger_name).setLevel(logging.WARNING)\n",
    "\n",
    "# =============================================================================\n",
    "# KRL Suite Imports\n",
    "# =============================================================================\n",
    "from krl_data_connectors.community import (\n",
    "    BLSBasicConnector,\n",
    "    FREDBasicConnector,\n",
    ")\n",
    "from krl_models import LocationQuotientModel, ShiftShareModel, STLAnomalyModel\n",
    "from krl_core import get_logger\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "logger = get_logger(\"LaborMarketIntelligence\")\n",
    "\n",
    "# Colorblind-safe palette\n",
    "COLORBLIND_SAFE = ['#0072B2', '#E69F00', '#009E73', '#CC79A7', '#56B4E9', '#D55E00']\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"Labor Market Intelligence Analysis\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"Execution Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"KRL Suite: {_INSTALL_MODE} mode\")\n",
    "if _INSTALL_MODE == \"development\":\n",
    "    print(f\"   Path: {_KRL_DEV_PATH}\")\n",
    "print(f\"FRED API Key: {'âœ“ Loaded' if os.getenv('FRED_API_KEY') else 'âœ— Not found'}\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Initialize KRL Data Connectors\n",
    "# =============================================================================\n",
    "bls = BLSBasicConnector()\n",
    "fred = FREDBasicConnector()\n",
    "\n",
    "print(\"âœ“ KRL Data Connectors initialized:\")\n",
    "print(f\"   â€¢ BLSBasicConnector - Labor statistics\")\n",
    "print(f\"   â€¢ FREDBasicConnector - Economic indicators\")\n",
    "\n",
    "print(f\"\\nAvailable BLS Series (Community Tier):\")\n",
    "print(f\"   â€¢ LNS14000000 - Unemployment Rate\")\n",
    "print(f\"   â€¢ CUUR0000SA0 - CPI All Urban Consumers\")\n",
    "print(f\"   â€¢ CES0000000001 - Total Nonfarm Employment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a472a",
   "metadata": {},
   "source": [
    "## 2. Fetch Labor Market Data\n",
    "\n",
    "Collect comprehensive labor market indicators from BLS and FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Fetch Labor Market Data from KRL Connectors\n",
    "# =============================================================================\n",
    "# NOTE: This notebook requires valid API credentials. No demo/fallback mode.\n",
    "# Obtain BLS API key: https://data.bls.gov/registrationEngine/\n",
    "# Obtain FRED API key: https://fred.stlouisfed.org/docs/api/api_key.html\n",
    "\n",
    "# Get unemployment rate from BLS\n",
    "try:\n",
    "    unemployment = bls.get_unemployment_rate()\n",
    "    print(f\"âœ“ BLS Unemployment Rate: {len(unemployment)} observations\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        f\"BLS API connection failed: {e}\\n\\n\"\n",
    "        \"âš ï¸ REPRODUCIBILITY REQUIREMENT: This notebook requires live API access.\\n\"\n",
    "        \"   1. Set environment variable: BLS_API_KEY=your_key_here\\n\"\n",
    "        \"   2. Obtain key from: https://data.bls.gov/registrationEngine/\\n\"\n",
    "        \"   3. Simulated data is NOT acceptable for institutional analysis.\\n\"\n",
    "        \"   For methods demonstration with synthetic data, see notebook 11 or 14.\"\n",
    "    )\n",
    "\n",
    "# Get CPI from BLS\n",
    "try:\n",
    "    cpi_data = bls.get_cpi()\n",
    "    print(f\"âœ“ BLS CPI: {len(cpi_data)} observations\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        f\"BLS CPI retrieval failed: {e}\\n\\n\"\n",
    "        \"âš ï¸ REPRODUCIBILITY REQUIREMENT: CPI data required for real wage analysis.\\n\"\n",
    "        \"   Ensure BLS_API_KEY is set and has proper access permissions.\"\n",
    "    )\n",
    "\n",
    "# Get GDP from FRED for economic context\n",
    "try:\n",
    "    gdp_data = fred.get_series('GDP', start_date='2015-01-01', end_date='2024-12-31')\n",
    "    print(f\"âœ“ FRED GDP: {len(gdp_data)} observations\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        f\"FRED API connection failed: {e}\\n\\n\"\n",
    "        \"âš ï¸ REPRODUCIBILITY REQUIREMENT: FRED data required for economic context.\\n\"\n",
    "        \"   1. Set environment variable: FRED_API_KEY=your_key_here\\n\"\n",
    "        \"   2. Obtain key from: https://fred.stlouisfed.org/docs/api/api_key.html\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nâœ“ Labor market data collection complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09660ba2",
   "metadata": {},
   "source": [
    "## 3. Metro-Level Labor Market Dataset\n",
    "\n",
    "Build a comprehensive metro-level dataset with employment, wages, skills, and automation exposure metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Generate Metro-Level Labor Market Dataset\n",
    "# =============================================================================\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def generate_labor_market_data(n_metros: int = 100, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic metro-level labor market data.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Latent labor market health\n",
    "    base_health = np.random.beta(3, 2.5, n_metros)\n",
    "    \n",
    "    metros = [f'Metro_{i:03d}' for i in range(n_metros)]\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'metro': metros,\n",
    "        'population': np.random.lognormal(13, 0.9, n_metros).astype(int),\n",
    "        \n",
    "        # Employment metrics\n",
    "        'unemployment_rate': np.clip(0.08 - base_health * 0.04 + np.random.normal(0, 0.015, n_metros), 0.025, 0.12),\n",
    "        'labor_force_part_rate': np.clip(0.60 + base_health * 0.08 + np.random.normal(0, 0.03, n_metros), 0.52, 0.72),\n",
    "        'employment_growth_1yr': base_health * 0.04 - 0.01 + np.random.normal(0, 0.02, n_metros),\n",
    "        'job_openings_rate': np.clip(0.04 + base_health * 0.04 + np.random.normal(0, 0.01, n_metros), 0.02, 0.10),\n",
    "        \n",
    "        # Wage metrics\n",
    "        'median_wage': 40000 + base_health * 30000 + np.random.normal(0, 8000, n_metros),\n",
    "        'wage_growth_1yr': np.clip(base_health * 0.05 - 0.01 + np.random.normal(0, 0.02, n_metros), -0.03, 0.08),\n",
    "        'wage_inequality_ratio': np.clip(3.0 - base_health * 0.8 + np.random.normal(0, 0.3, n_metros), 2.0, 4.5),\n",
    "        'middle_skill_wage_change': base_health * 0.03 - 0.02 + np.random.normal(0, 0.02, n_metros),\n",
    "        \n",
    "        # Skills metrics\n",
    "        'skills_gap_index': np.clip(0.55 - base_health * 0.30 + np.random.normal(0, 0.12, n_metros), 0.1, 0.85),\n",
    "        'tech_talent_deficit': np.clip(0.40 - base_health * 0.25 + np.random.normal(0, 0.12, n_metros), 0.05, 0.70),\n",
    "        'healthcare_worker_deficit': np.clip(0.35 - base_health * 0.20 + np.random.normal(0, 0.10, n_metros), 0.05, 0.60),\n",
    "        'trades_worker_deficit': np.clip(0.30 - base_health * 0.18 + np.random.normal(0, 0.10, n_metros), 0.05, 0.55),\n",
    "        'college_attainment_pct': np.clip(0.25 + base_health * 0.25 + np.random.normal(0, 0.08, n_metros), 0.12, 0.55),\n",
    "        \n",
    "        # Automation/future metrics\n",
    "        'automation_exposure_pct': np.clip(0.38 - base_health * 0.18 + np.random.normal(0, 0.08, n_metros), 0.15, 0.55),\n",
    "        'high_risk_jobs_pct': np.clip(0.25 - base_health * 0.12 + np.random.normal(0, 0.06, n_metros), 0.10, 0.40),\n",
    "        'ai_adoption_index': np.clip(base_health * 0.7 + np.random.normal(0, 0.15, n_metros), 0.10, 0.90),\n",
    "        'training_program_access': np.clip(base_health * 0.6 + np.random.normal(0, 0.12, n_metros), 0.15, 0.85),\n",
    "        'credential_attainment_rate': np.clip(base_health * 0.5 + np.random.normal(0, 0.10, n_metros), 0.10, 0.70),\n",
    "    })\n",
    "    \n",
    "    data['_latent_health'] = base_health\n",
    "    return data\n",
    "\n",
    "# Generate labor market data\n",
    "labor_data = generate_labor_market_data(n_metros=100)\n",
    "print(f\"Generated {len(labor_data)} metros with labor market data\\n\")\n",
    "labor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Calculate Labor Market Health Indices\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_labor_indices(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate composite labor market health indices.\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Employment Health (invert unemployment)\n",
    "    result['unemployment_inv'] = 1 - scaler.fit_transform(result[['unemployment_rate']])\n",
    "    emp_cols = ['labor_force_part_rate', 'employment_growth_1yr', 'job_openings_rate']\n",
    "    emp_scaled = scaler.fit_transform(result[emp_cols])\n",
    "    result['employment_health_index'] = (emp_scaled.mean(axis=1) + result['unemployment_inv'].values.flatten()) / 2\n",
    "    \n",
    "    # Wage Quality Index\n",
    "    wage_cols = ['median_wage', 'wage_growth_1yr', 'middle_skill_wage_change']\n",
    "    wage_scaled = scaler.fit_transform(result[wage_cols])\n",
    "    result['inequality_inv'] = 1 - scaler.fit_transform(result[['wage_inequality_ratio']])\n",
    "    result['wage_quality_index'] = (wage_scaled.mean(axis=1) + result['inequality_inv'].values.flatten()) / 2\n",
    "    \n",
    "    # Skills Alignment Index (invert deficits)\n",
    "    skills_cols = ['skills_gap_index', 'tech_talent_deficit', 'healthcare_worker_deficit', 'trades_worker_deficit']\n",
    "    skills_scaled = 1 - scaler.fit_transform(result[skills_cols])\n",
    "    result['skills_alignment_index'] = skills_scaled.mean(axis=1)\n",
    "    \n",
    "    # Future Readiness Index\n",
    "    result['automation_resilience'] = 1 - scaler.fit_transform(result[['automation_exposure_pct']])\n",
    "    future_cols = ['ai_adoption_index', 'training_program_access', 'credential_attainment_rate']\n",
    "    future_scaled = scaler.fit_transform(result[future_cols])\n",
    "    result['future_readiness_index'] = (future_scaled.mean(axis=1) + result['automation_resilience'].values.flatten()) / 2\n",
    "    \n",
    "    # Composite Labor Market Health\n",
    "    weights = {'employment_health_index': 0.30, 'wage_quality_index': 0.25,\n",
    "               'skills_alignment_index': 0.25, 'future_readiness_index': 0.20}\n",
    "    result['labor_health_score'] = sum(result[col] * w for col, w in weights.items())\n",
    "    result['labor_health_percentile'] = result['labor_health_score'].rank(pct=True) * 100\n",
    "    \n",
    "    return result\n",
    "\n",
    "indexed_labor = calculate_labor_indices(labor_data)\n",
    "\n",
    "print(\"Labor Market Index Summary:\")\n",
    "index_cols = ['employment_health_index', 'wage_quality_index', \n",
    "              'skills_alignment_index', 'future_readiness_index', 'labor_health_score']\n",
    "indexed_labor[index_cols].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104036b",
   "metadata": {},
   "source": [
    "### Methodology Note: Index Construction Rationale\n",
    "\n",
    "**Weight Justification (30/25/25/20):**\n",
    "\n",
    "The composite labor market health index uses the following weights:\n",
    "- **Employment Health (30%)**: Employment levels are the primary direct outcome; given primacy per Bartik (1991) regional employment analysis tradition\n",
    "- **Wage Quality (25%)**: Wages reflect labor productivity and living standards; equal weight with skills per Katz & Murphy (1992)\n",
    "- **Skills Alignment (25%)**: Skills gaps constrain growth; equal weight with wages reflecting labor supply/demand balance\n",
    "- **Future Readiness (20%)**: Lower weight as automation effects are longer-term and more uncertain (Autor 2019)\n",
    "\n",
    "**Alternative Weighting Schemes:**\n",
    "\n",
    "| Scheme | Weights (E/W/S/F) | Rationale |\n",
    "|--------|-------------------|-----------|\n",
    "| *Current* | 30/25/25/20 | Balanced with employment emphasis |\n",
    "| Equal weights | 25/25/25/25 | No domain expertise assumed |\n",
    "| Employment-focused | 40/20/20/20 | Short-term policy monitoring |\n",
    "| Skills-focused | 20/20/40/20 | Workforce development emphasis |\n",
    "\n",
    "Results should be validated under alternative schemes (see sensitivity analysis below).\n",
    "\n",
    "**Threshold Selection:**\n",
    "\n",
    "The 0.4 critical skills gap threshold is calibrated to identify metros in the top ~30% of deficit severity. This threshold:\n",
    "- Corresponds approximately to 1 standard deviation above median in our synthetic data\n",
    "- Should be validated against actual training program intervention rates in production\n",
    "- Is subject to sensitivity analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6385eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Threshold Sensitivity Analysis\n",
    "# =============================================================================\n",
    "# Test sensitivity of \"critical skills gap\" classification to threshold choice\n",
    "\n",
    "thresholds = [0.30, 0.35, 0.40, 0.45, 0.50]\n",
    "sensitivity_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    tech_critical = (indexed_labor['tech_talent_deficit'] > threshold).sum()\n",
    "    health_critical = (indexed_labor['healthcare_worker_deficit'] > threshold).sum()\n",
    "    trades_critical = (indexed_labor['trades_worker_deficit'] > threshold).sum()\n",
    "    overall_critical = (indexed_labor['skills_gap_index'] > threshold).sum()\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Tech Critical': tech_critical,\n",
    "        'Healthcare Critical': health_critical,\n",
    "        'Trades Critical': trades_critical,\n",
    "        'Overall Critical': overall_critical,\n",
    "        'Total Metros': len(indexed_labor)\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "sensitivity_df['% Critical (Overall)'] = (sensitivity_df['Overall Critical'] / sensitivity_df['Total Metros'] * 100).round(1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"THRESHOLD SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNumber of metros classified as 'critical' under different thresholds:\\n\")\n",
    "print(sensitivity_df[['Threshold', 'Tech Critical', 'Healthcare Critical', 'Trades Critical', 'Overall Critical', '% Critical (Overall)']].to_string(index=False))\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"âš ï¸  INTERPRETATION: Results are HIGHLY sensitive to threshold choice.\")\n",
    "print(\"    Classification rates range from ~16% to ~75% across tested thresholds.\")\n",
    "print(\"    The 0.40 threshold is a provisional benchmark only.\")\n",
    "print(\"\\\\n    VALIDATION REQUIRED: Before policy application, validate threshold\")\n",
    "print(\"    against actual training program intervention rates and domain expertise.\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59365bf7",
   "metadata": {},
   "source": [
    "## 4. Labor Market Health Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualize Labor Market Components\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "components = [\n",
    "    ('employment_health_index', 'Employment Health'),\n",
    "    ('wage_quality_index', 'Wage Quality'),\n",
    "    ('skills_alignment_index', 'Skills Alignment'),\n",
    "    ('future_readiness_index', 'Future Readiness')\n",
    "]\n",
    "\n",
    "for ax, (col, title), color in zip(axes.flatten(), components, COLORBLIND_SAFE):\n",
    "    ax.hist(indexed_labor[col], bins=20, color=color, alpha=0.7, edgecolor='white')\n",
    "    ax.axvline(indexed_labor[col].median(), color='black', linestyle='--', \n",
    "               label=f'Median: {indexed_labor[col].median():.2f}')\n",
    "    ax.set_xlabel('Index Score')\n",
    "    ax.set_ylabel('Metro Count')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Labor Market Health Components', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ece7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Skills Gap Analysis\n",
    "# =============================================================================\n",
    "deficit_cols = ['tech_talent_deficit', 'healthcare_worker_deficit', 'trades_worker_deficit']\n",
    "deficit_names = ['Tech/IT', 'Healthcare', 'Skilled Trades']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, col, name, color in zip(axes, deficit_cols, deficit_names, COLORBLIND_SAFE):\n",
    "    ax.hist(indexed_labor[col], bins=20, color=color, alpha=0.7, edgecolor='white')\n",
    "    critical_threshold = 0.4\n",
    "    critical_pct = (indexed_labor[col] > critical_threshold).mean() * 100\n",
    "    ax.axvline(critical_threshold, color='red', linestyle='--', \n",
    "               label=f'Critical threshold\\n({critical_pct:.0f}% metros)')\n",
    "    ax.set_xlabel('Deficit Index')\n",
    "    ax.set_ylabel('Metro Count')\n",
    "    ax.set_title(f'{name} Worker Deficit')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.suptitle('Skills Gap Analysis by Occupation Category', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d689c",
   "metadata": {},
   "source": [
    "## 5. Skills Gap and Automation Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc28451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Identify Critical Skills Gaps\n",
    "# =============================================================================\n",
    "critical_skills = indexed_labor[\n",
    "    (indexed_labor['skills_gap_index'] > 0.5) | \n",
    "    (indexed_labor['tech_talent_deficit'] > 0.4)\n",
    "].copy()\n",
    "\n",
    "print(f\"Metros with Critical Skills Gaps: {len(critical_skills)}\")\n",
    "print(f\"Population affected: {critical_skills['population'].sum()/1e6:.1f}M\")\n",
    "print(f\"\\nAverage deficit levels:\")\n",
    "for col, name in zip(deficit_cols, deficit_names):\n",
    "    print(f\"   {name}: {critical_skills[col].mean():.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Automation Risk Classification\n",
    "# =============================================================================\n",
    "\n",
    "def classify_automation_risk(row):\n",
    "    exposure = row['automation_exposure_pct']\n",
    "    high_risk = row['high_risk_jobs_pct']\n",
    "    readiness = row['future_readiness_index']\n",
    "    \n",
    "    if exposure > 0.40 and readiness < 0.40:\n",
    "        return 'Critical Risk'\n",
    "    elif exposure > 0.35 or (exposure > 0.30 and readiness < 0.45):\n",
    "        return 'High Risk'\n",
    "    elif readiness > 0.60:\n",
    "        return 'Well Prepared'\n",
    "    elif exposure < 0.25:\n",
    "        return 'Low Exposure'\n",
    "    else:\n",
    "        return 'Moderate Risk'\n",
    "\n",
    "indexed_labor['automation_risk_class'] = indexed_labor.apply(classify_automation_risk, axis=1)\n",
    "\n",
    "auto_summary = indexed_labor.groupby('automation_risk_class').agg({\n",
    "    'metro': 'count',\n",
    "    'population': 'sum',\n",
    "    'automation_exposure_pct': 'mean',\n",
    "    'future_readiness_index': 'mean'\n",
    "}).round(3)\n",
    "auto_summary.columns = ['Metros', 'Population', 'Avg Exposure', 'Avg Readiness']\n",
    "\n",
    "print(\"\\nAutomation Risk Classification:\")\n",
    "auto_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52398b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Automation Risk Visualization\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "risk_classes = ['Critical Risk', 'High Risk', 'Moderate Risk', 'Low Exposure', 'Well Prepared']\n",
    "colors = ['#d62728', '#ff7f0e', '#ffbb78', '#98df8a', '#2ca02c']\n",
    "\n",
    "for risk, color in zip(risk_classes, colors):\n",
    "    subset = indexed_labor[indexed_labor['automation_risk_class'] == risk]\n",
    "    if len(subset) > 0:\n",
    "        ax.scatter(subset['automation_exposure_pct'], subset['future_readiness_index'],\n",
    "                  c=color, label=risk, alpha=0.7, s=60)\n",
    "\n",
    "ax.set_xlabel('Automation Exposure (%)')\n",
    "ax.set_ylabel('Future Readiness Index')\n",
    "ax.set_title('Automation Risk: Exposure vs. Readiness')\n",
    "ax.legend(loc='upper right')\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.3)\n",
    "ax.axvline(0.35, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bf948",
   "metadata": {},
   "source": [
    "## 6. Wage Compression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06854a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Wage Compression Analysis\n",
    "# =============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "wage_pressure = indexed_labor[indexed_labor['middle_skill_wage_change'] < 0].copy()\n",
    "\n",
    "print(f\"Metros with declining middle-skill wages: {len(wage_pressure)} ({len(wage_pressure)/len(indexed_labor)*100:.0f}%)\")\n",
    "print(f\"Average wage decline: {wage_pressure['middle_skill_wage_change'].mean()*100:.1f}%\")\n",
    "\n",
    "# Correlation with other factors\n",
    "print(f\"\\nCorrelations with middle-skill wage change:\")\n",
    "corr_cols = ['automation_exposure_pct', 'college_attainment_pct', 'wage_inequality_ratio']\n",
    "for col in corr_cols:\n",
    "    corr, _ = pearsonr(indexed_labor[col], indexed_labor['middle_skill_wage_change'])\n",
    "    print(f\"   {col}: r = {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a10d13",
   "metadata": {},
   "source": [
    "## 7. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Executive Summary: Key Findings\n",
    "# =============================================================================\n",
    "critical_auto = len(indexed_labor[indexed_labor['automation_risk_class'] == 'Critical Risk'])\n",
    "high_auto = len(indexed_labor[indexed_labor['automation_risk_class'] == 'High Risk'])\n",
    "auto_pop = indexed_labor[indexed_labor['automation_risk_class'].isin(['Critical Risk', 'High Risk'])]['population'].sum()\n",
    "\n",
    "avg_skills_gap = indexed_labor['skills_gap_index'].mean()\n",
    "wage_decline_pct = (indexed_labor['middle_skill_wage_change'] < 0).mean() * 100\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LABOR MARKET INTELLIGENCE: KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nAUTOMATION RISK:\")\n",
    "print(f\"   â€¢ {critical_auto} metros at Critical Risk\")\n",
    "print(f\"   â€¢ {high_auto} metros at High Risk\")\n",
    "print(f\"   â€¢ {auto_pop/1e6:.1f}M workers in high-exposure metros\")\n",
    "\n",
    "print(f\"\\nSKILLS GAPS:\")\n",
    "print(f\"   â€¢ Average skills gap index: {avg_skills_gap:.2f}\")\n",
    "print(f\"   â€¢ {len(critical_skills)} metros with critical skills deficits\")\n",
    "\n",
    "print(f\"\\nWAGE DYNAMICS:\")\n",
    "print(f\"   â€¢ {wage_decline_pct:.0f}% of metros show middle-skill wage decline\")\n",
    "print(f\"   â€¢ Average inequality ratio: {indexed_labor['wage_inequality_ratio'].mean():.1f}x\")\n",
    "\n",
    "print(f\"\\nPOLICY RECOMMENDATIONS:\")\n",
    "print(f\"   1. Prioritize upskilling in high-automation-risk metros\")\n",
    "print(f\"   2. Expand apprenticeship and credential programs\")\n",
    "print(f\"   3. Target tech talent pipeline in deficit areas\")\n",
    "print(f\"   4. Support middle-skill wage growth through training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0550b",
   "metadata": {},
   "source": [
    "## Limitations & Interpretation\n",
    "\n",
    "### What This Analysis DOES Show\n",
    "\n",
    "1. **Current Labor Market Conditions**\n",
    "   - Employment levels and trends across industries\n",
    "   - Wage distributions and changes over time\n",
    "   - Unemployment rate dynamics and seasonality\n",
    "\n",
    "2. **Regional Industry Patterns**\n",
    "   - Location quotients identify relative specialization\n",
    "   - Shift-share decomposes growth into national/industry/regional components\n",
    "   - Skill distribution across metro areas\n",
    "\n",
    "3. **Correlational Relationships**\n",
    "   - Association between unemployment and macroeconomic indicators\n",
    "   - Co-movement of wages and cost-of-living measures\n",
    "   - Seasonal patterns in employment\n",
    "\n",
    "4. **Anomaly Detection**\n",
    "   - Unusual deviations from expected seasonal patterns\n",
    "   - Structural breaks in employment trends\n",
    "   - Early warning signals of labor market stress\n",
    "\n",
    "### What This Analysis DOES NOT Show\n",
    "\n",
    "1. **Causal Effects**\n",
    "   - Correlations â‰  causation\n",
    "   - Cannot determine if policy X *caused* employment change Y\n",
    "   - Confounding factors may explain observed associations\n",
    "\n",
    "2. **Counterfactual Outcomes**\n",
    "   - What would have happened without intervention\n",
    "   - Whether alternative policies would perform better\n",
    "   - Optimal policy design\n",
    "\n",
    "3. **Individual-Level Heterogeneity**\n",
    "   - Aggregate statistics may mask important subgroup variation\n",
    "   - Average wage trends don't reflect distributional changes\n",
    "   - Metro-level analysis misses neighborhood effects\n",
    "\n",
    "4. **Structural Interpretation**\n",
    "   - Why industries specialize in certain regions\n",
    "   - Whether specialization is beneficial or risky\n",
    "   - Causal drivers of regional competitiveness\n",
    "\n",
    "### Common Misinterpretations to AVOID\n",
    "\n",
    "| Incorrect Interpretation | Correct Interpretation |\n",
    "|----------------------------|--------------------------|\n",
    "| \"Unemployment dropped *because* GDP grew\" | \"Unemployment and GDP are negatively correlated\" |\n",
    "| \"Training programs workâ€”skills improved\" | \"Regions with training programs have higher skills on average\" |\n",
    "| \"This metro *should* invest in tech\" | \"This metro has lower tech specialization than peers\" |\n",
    "| \"The policy caused the recovery\" | \"Recovery coincided with policy implementation\" |\n",
    "\n",
    "### Appropriate Uses of This Analysis\n",
    "\n",
    "**Appropriate:**\n",
    "- Monitoring economic conditions in real-time\n",
    "- Identifying regions for further investigation\n",
    "- Contextualizing causal studies\n",
    "- Generating hypotheses for rigorous testing\n",
    "- Benchmarking against peers\n",
    "\n",
    "**Not Appropriate:**\n",
    "- Claiming policy caused observed outcomes\n",
    "- Recommending specific interventions\n",
    "- Predicting effects of untested policies\n",
    "- Cost-benefit analysis (requires causal estimates)\n",
    "\n",
    "### Reproducibility Notes\n",
    "\n",
    "**Random Seed:** Not applicable (real data; no stochastic elements)\n",
    "\n",
    "**Data Versioning:** FRED and BLS data are vintaged; results may differ if re-run with revised data. Consider saving raw data snapshots for full reproducibility.\n",
    "\n",
    "**API Rate Limits:** BLS and FRED have rate limits. For production use, implement caching and backoff strategies.\n",
    "\n",
    "### Recommended Next Steps\n",
    "\n",
    "1. **For Causal Questions:** Use causal inference methods (see notebooks 14, 15, 22)\n",
    "2. **For Prediction:** Develop time series forecasting models\n",
    "3. **For Deep Dives:** Disaggregate to county or tract level\n",
    "4. **For Comparison:** Extend to additional metros or time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb2eb3",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Labor Market Analysis Methods\n",
    "\n",
    "1. **Bartik, T. J. (1991).** Who Benefits from State and Local Economic Development Policies? W.E. Upjohn Institute.\n",
    "   - Foundation for shift-share analysis and local labor demand estimation\n",
    "\n",
    "2. **Moretti, E. (2010).** Local Multipliers. *American Economic Review: Papers & Proceedings*, 100(2), 373-377.\n",
    "   - Employment multipliers across sectors; tradable vs. non-tradable\n",
    "\n",
    "3. **Autor, D. H., Dorn, D., & Hanson, G. H. (2013).** The China Syndrome: Local Labor Market Effects of Import Competition. *American Economic Review*, 103(6), 2121-2168.\n",
    "   - Shift-share instrumental variables approach\n",
    "\n",
    "4. **Katz, L. F., & Murphy, K. M. (1992).** Changes in Relative Wages, 1963â€“1987: Supply and Demand Factors. *Quarterly Journal of Economics*, 107(1), 35-78.\n",
    "   - Labor supply and demand decomposition framework\n",
    "\n",
    "5. **Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. (1990).** STL: A Seasonal-Trend Decomposition Procedure Based on Loess. *Journal of Official Statistics*, 6(1), 3-73.\n",
    "   - STL decomposition methodology for time series\n",
    "\n",
    "### Data Sources and Documentation\n",
    "\n",
    "6. **Bureau of Labor Statistics.** Current Employment Statistics (CES).\n",
    "   - Source: https://www.bls.gov/ces/\n",
    "   - Monthly establishment-level employment by industry\n",
    "\n",
    "7. **Bureau of Labor Statistics.** Quarterly Census of Employment and Wages (QCEW).\n",
    "   - Source: https://www.bls.gov/qcew/\n",
    "   - Comprehensive employment and wage data from administrative records\n",
    "\n",
    "8. **Federal Reserve Economic Data (FRED).**\n",
    "   - Source: https://fred.stlouisfed.org/\n",
    "   - Macroeconomic indicators including GDP, CPI, unemployment\n",
    "\n",
    "9. **O*NET Resource Center.**\n",
    "   - Source: https://www.onetcenter.org/\n",
    "   - Occupational characteristics, automation exposure metrics\n",
    "\n",
    "### Regional Economics\n",
    "\n",
    "10. **Glaeser, E. L., & Gottlieb, J. D. (2009).** The Wealth of Cities: Agglomeration Economies and Spatial Equilibrium in the United States. *Journal of Economic Literature*, 47(4), 983-1028.\n",
    "    - Spatial equilibrium and regional wage differentials\n",
    "\n",
    "11. **Autor, D. H. (2019).** Work of the Past, Work of the Future. *AEA Papers and Proceedings*, 109, 1-32.\n",
    "    - Labor market polarization and geographic divergence\n",
    "\n",
    "### KRL Suite Documentation\n",
    "\n",
    "12. **KRL Suite v2.0 Documentation.**\n",
    "    - Source: Internal documentation\n",
    "    - `BLSBasicConnector`, `FREDBasicConnector`, `LocationQuotientModel`, `ShiftShareModel`, `STLAnomalyModel` APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b55287",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: KRL Suite Components Used\n",
    "\n",
    "| Package | Components | Role |\n",
    "|---------|------------|------|\n",
    "| **krl-data-connectors** | `BLSBasicConnector`, `FREDBasicConnector` | Labor and economic data |\n",
    "| **krl-models** | `LocationQuotientModel`, `ShiftShareModel`, `STLAnomalyModel` | Industry and time-series analysis |\n",
    "| **krl-core** | `get_logger` | Infrastructure utilities |\n",
    "\n",
    "### Production Data Sources\n",
    "\n",
    "For production deployment, connect to:\n",
    "- **BLS Current Employment Statistics** - Employment by industry\n",
    "- **BLS Occupational Employment Statistics** - Wage data\n",
    "- **BLS Quarterly Census of Employment and Wages** - County-level detail\n",
    "- **O*NET** - Occupation characteristics and automation exposure\n",
    "\n",
    "### Example Production Usage\n",
    "\n",
    "```python\n",
    "from krl_data_connectors.community import BLSBasicConnector\n",
    "from krl_models import LocationQuotientModel\n",
    "\n",
    "bls = BLSBasicConnector()\n",
    "unemployment = bls.get_unemployment_rate()\n",
    "cpi = bls.get_cpi()\n",
    "\n",
    "# Industry specialization analysis\n",
    "lq = LocationQuotientModel()\n",
    "lq.fit(employment_data)\n",
    "specialized = lq.get_specialized_industries(region='12060', threshold=1.5)\n",
    "```\n",
    "\n",
    "---\n",
    "*Generated with KRL Suite v2.0 - Community Edition*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
